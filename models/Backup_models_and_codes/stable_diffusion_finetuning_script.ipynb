{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dccfa9a-8e09-4654-bb29-d2f25df888fb",
   "metadata": {
    "id": "3dccfa9a-8e09-4654-bb29-d2f25df888fb"
   },
   "source": [
    "# Dreambooth inpainting finetuning\n",
    "\n",
    "Finetune Stable Diffusion inpainting model on custom images. Replace custom mask in any image with finetuned object.\n",
    "\n",
    "1. **Fine-tuning Stable Diffusion inpainting model on custom images:** Stable Diffusion is a state-of-the-art machine learning model, used for the purpose of image inpainting. Inpainting is a process that involves filling in the missing part of any image using the existing data. In this snippet, the Stable Diffusion model is being fine-tuned on custom images.\n",
    "\n",
    "2. **Replace mask in any image with the fine-tuned object:** After the fine-tuning process, the subsequent task is to use the fine-tuned model to replace the mask in any image with the fine-tuned object. This essentially means replacing a part of any image, marked by a mask, with the object generated by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a7ba5-e7c6-453f-b833-b15a78c96bf8",
   "metadata": {
    "id": "8a1a7ba5-e7c6-453f-b833-b15a78c96bf8"
   },
   "outputs": [],
   "source": [
    "!pip install -U diffusers transformers ftfy gradio accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01724268-0811-46a5-8a50-2017d70c59a2",
   "metadata": {
    "id": "01724268-0811-46a5-8a50-2017d70c59a2"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7185064b-e88e-4b2d-a9eb-d6b939668ffb",
   "metadata": {
    "id": "7185064b-e88e-4b2d-a9eb-d6b939668ffb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-10-12 02:17:27--  https://raw.githubusercontent.com/huggingface/diffusers/main/examples/research_projects/dreambooth_inpaint/train_dreambooth_inpaint.py\n",
      "Loaded CA certificate '/usr/ssl/certs/ca-bundle.crt'\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33292 (33K) [text/plain]\n",
      "Saving to: 'train_dreambooth_inpaint.py'\n",
      "\n",
      "     0K .......... .......... .......... ..                   100% 1.22M=0.03s\n",
      "\n",
      "2024-10-12 02:17:29 (1.22 MB/s) - 'train_dreambooth_inpaint.py' saved [33292/33292]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/huggingface/diffusers/main/examples/research_projects/dreambooth_inpaint/train_dreambooth_inpaint.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9101b646-d981-432b-b650-dddc7a6c9aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/davide97l/stable_diffusion_dreambooth_inpainting.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "933e3880-bc8e-443d-9b75-4f4bf3d49b8e",
   "metadata": {
    "id": "933e3880-bc8e-443d-9b75-4f4bf3d49b8e"
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "from typing import List, Optional, Union\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import PIL\n",
    "\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "463b329b-31da-4764-9c28-7f1028a7c8dc",
   "metadata": {
    "id": "463b329b-31da-4764-9c28-7f1028a7c8dc"
   },
   "outputs": [],
   "source": [
    "def image_grid(imgs, rows, cols, resize=256):\n",
    "    if resize is not None:\n",
    "        imgs = [img.resize((resize, resize)) for img in imgs]\n",
    "    w, h = imgs[0].size\n",
    "    grid = PIL.Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    grid_w, grid_h = grid.size\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e5d7bc4-36bc-48d2-99c2-0f3857478b16",
   "metadata": {
    "id": "6e5d7bc4-36bc-48d2-99c2-0f3857478b16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: C:\\Users\\hassa\\Desktop\\Uni\\Finalized Models\\models\\inpainting\\./Stable_Diffusion_Inpaint_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b518aca3c1df4cb9b1312cf2981b0a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_dir = os.getcwd()\n",
    "model_path = os.path.join(base_dir, './Stable_Diffusion_Inpaint_2')\n",
    "\n",
    "print(\"Loading model from:\", model_path)\n",
    "\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ")\n",
    "\n",
    "pipe.enable_attention_slicing()\n",
    "\n",
    "# Move the pipeline to the correct device (GPU if available)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42109257-9433-4fc0-ae8a-3a42ed529c46",
   "metadata": {
    "id": "42109257-9433-4fc0-ae8a-3a42ed529c46"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde26f8112324b648792ad95b3ff155b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b443e41-0c20-4958-993a-6a62c63d8852",
   "metadata": {
    "id": "3b443e41-0c20-4958-993a-6a62c63d8852"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "2024-10-12 02:23:15.151001: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-12 02:23:16.831609: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]\n",
      "Steps:   0%|          | 0/500 [00:00<?, ?it/s]C:\\Users\\hassa\\anaconda3\\envs\\clean-tf\\lib\\site-packages\\diffusers\\models\\attention_processor.py:2358: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  hidden_states = F.scaled_dot_product_attention(\n",
      "C:\\Users\\hassa\\anaconda3\\envs\\clean-tf\\lib\\site-packages\\torch\\utils\\checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "\n",
      "Steps:   0%|          | 0/500 [00:17<?, ?it/s, loss=0.00719, lr=5e-6]Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hassa\\Desktop\\Uni\\Finalized Models\\models\\inpainting\\train_dreambooth_inpaint.py\", line 812, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\hassa\\Desktop\\Uni\\Finalized Models\\models\\inpainting\\train_dreambooth_inpaint.py\", line 767, in main\n",
      "    optimizer.step()\n",
      "  File \"C:\\Users\\hassa\\anaconda3\\envs\\clean-tf\\lib\\site-packages\\accelerate\\optimizer.py\", line 171, in step\n",
      "    self.optimizer.step(closure)\n",
      "  File \"C:\\Users\\hassa\\anaconda3\\envs\\clean-tf\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"C:\\Users\\hassa\\anaconda3\\envs\\clean-tf\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\hassa\\anaconda3\\envs\\clean-tf\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 89, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\hassa\\anaconda3\\envs\\clean-tf\\lib\\site-packages\\torch\\optim\\adamw.py\", line 216, in step\n",
      "    has_complex = self._init_group(\n",
      "  File \"C:\\Users\\hassa\\anaconda3\\envs\\clean-tf\\lib\\site-packages\\torch\\optim\\adamw.py\", line 159, in _init_group\n",
      "    state[\"exp_avg_sq\"] = torch.zeros_like(\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.51 GiB is allocated by PyTorch, and 87.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "Steps:   0%|          | 0/500 [00:39<?, ?it/s, loss=0.00719, lr=5e-6]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hassa\\anaconda3\\envs\\clean-tf\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\hassa\\anaconda3\\envs\\clean-tf\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\hassa\\anaconda3\\envs\\clean-tf\\Scripts\\accelerate.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\hassa\\anaconda3\\envs\\clean-tf\\lib\\site-packages\\accelerate\\commands\\accelerate_cli.py\", line 48, in main\n",
      "    args.func(args)\n",
      "  File \"C:\\Users\\hassa\\anaconda3\\envs\\clean-tf\\lib\\site-packages\\accelerate\\commands\\launch.py\", line 1168, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"C:\\Users\\hassa\\anaconda3\\envs\\clean-tf\\lib\\site-packages\\accelerate\\commands\\launch.py\", line 763, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['C:\\\\Users\\\\hassa\\\\anaconda3\\\\envs\\\\clean-tf\\\\python.exe', 'train_dreambooth_inpaint.py', '--pretrained_model_name_or_path=./Stable_Diffusion_Inpaint_2', '--instance_data_dir=images/Images_jpg', '--output_dir=stable-diffusion-inpainting-painting', '--instance_prompt=old painting', '--resolution=256', '--mixed_precision=no', '--train_batch_size=1', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--max_train_steps=500', '--gradient_accumulation_steps=2', '--gradient_checkpointing', '--train_text_encoder', '--seed=0', '--push_to_hub']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch train_dreambooth_inpaint.py \\\n",
    "    --pretrained_model_name_or_path=\"./Stable_Diffusion_Inpaint_2\"  \\\n",
    "    --instance_data_dir=\"images/Images_jpg\" \\\n",
    "    --output_dir=\"stable-diffusion-inpainting-painting\" \\\n",
    "    --instance_prompt=\"old painting\" \\\n",
    "    --resolution=256 \\\n",
    "    --mixed_precision=\"no\" \\\n",
    "    --train_batch_size=1 \\\n",
    "    --learning_rate=5e-6 \\\n",
    "    --lr_scheduler=\"constant\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --max_train_steps=500 \\\n",
    "    --gradient_accumulation_steps=2 \\\n",
    "    --gradient_checkpointing \\\n",
    "    --train_text_encoder \\\n",
    "    --seed=\"0\" \\\n",
    "    --push_to_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8197e4-705c-4606-afd3-64b82ba44071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (clean-tf)",
   "language": "python",
   "name": "clean-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
